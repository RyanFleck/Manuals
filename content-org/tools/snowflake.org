#+LAYOUT: docs-manual
#+TITLE: Snowflake
#+SUMMARY:
#+hugo_base_dir: ../../
#+hugo_section: tools
#+hugo_custom_front_matter: :toc true :summary "A modern data engineering platform."
#+hugo_custom_front_matter: :chapter true
#+hugo_custom_front_matter: :aliases '("/snow" "/sf" "/snowflake" "/sn")
#+hugo_custom_front_matter: :warning "THIS FILE WAS GENERATED BY OX-HUGO, DO NOT EDIT!!!"
#+PROPERTY: header-args:python :exports both :eval yes :results value scalar
#+hugo_level_offset: 0
#+STARTUP: showall

* Snowflake

*Snowflake* is a cloud native database that provides a wealth of
analytical and data mining features for processing, integrating, and
presenting data. *Data platform* could be used to describe Snowflake, as
it offers features traditionally found in data warehouses, lakes, and
streaming-processing platforms like Kafka.

#+hugo: more

** COF-C02 - Snowpro Core Certification

You can download the study guide for this exam on the [[https://learn.snowflake.com/en/certifications/snowpro-core][Snowflake
COF-C02 Exam Guide]] page. This guide is updated frequently, so go and
request your own copy if possible. It is a 100-question, 115-minute test.

* Why Snowflake?
:PROPERTIES:
:ID:       5ce4639d-0017-45d7-a564-d8625c516fc5
:END:

The shortcomings of traditional data analytics environments have been
addressed with Snowflake's ease of storage, retrieval, and analysis of
large quantities of client data.

*Topics:*

- Fully managed: no hardware or server provisioning required
- Compute / storage decoupled
- Auto-scaling, auto-suspend, etc.
- Support for semi-structured data (JSON, VARIANT, etc.)
- Zero-copy cloning, time travel, data sharing
- Strong ecosystem and connector support

* Key Concepts & Architecture
:PROPERTIES:
:ID:       2238eb3b-bd76-4f84-8c95-e4f7e8a206af
:END:

*Topics:*

- Snowsight UI (web interface)
  - Worksheets: old UI, now *Workspaces* (UI: Projects => Workspaces).
  - Workspaces can be synchronized with Git.
- SnowSQL (CLI)
- Notebooks (Snowflake Notebooks)
- Architecture: hybrid of shared-disk and shared-nothing.
  - Central storage + multiple MPP compute clusters.
- Snowflake Documentation
- Cloud Platforms: Runs on AWS, Azure, or GCP.
- Snowflake Documentation
- Micro-partitions (internal detail)
- Compute / Storage separation
- Zero-copy cloning, Time Travel, Fail-safe

** Multi-Cluster Shared Data Architecture

Typical distributed architectures like shared-disk or shared-nothing
keep independent copies of data locally, which are synchronized, or
kept at a single point for shared-disk. Shared-disk has the downside
of a fragile single point of failure, where shared-noting is expensive
to keep synchronized and easy to over-provision. Snowflake takes a
different approach by segregating the system into layers, called
/"Multi-cluster Shared Data Architecture"/:

1. *Data Storage*
2. *Query Processing* (Virtual Warehouses)
3. *Cloud Services*

This separation allows each layer to scale entirely independently.

*** Data Storage Layer

Snowflake data is stored in a *column-oriented, partitioned, encrypted
format* highly optimized for the blob storage it is written to.

By default, strong *AES-256* encryption is applied to data written to
the backing blob storage. Snowflake inherits the durability and
availability guarantees provided by their backing services - in the
case of Snowflake's proprietary columnar storage format[fn:1], AWS S3
blob storage.

Snowflake divides written files into *micro-partitions* so only columns
that must be read or written are loaded during a query.

Table data is billed at a flat rate per month, and only accessible via
Snowflake queries.


*** Query Processing Layer

*Virtual Warehouses* in the query processing layer cache table data
required for queries locally, while leaving the majority of data in
storage. Queries are executed in these warehouses, which are EC2[fn:2]
instances provisioned by Snowflake in an ephemeral manner.

*Small - 6XL* warehouse sizes (t-shirt sizes) are available.

Even with many warehouses operating on the data, Snowflake uses an
[[https://www.mongodb.com/resources/products/capabilities/acid-compliance][ACID]] compliant global layer (the *transaction manager*)to ensure the
data from each transaction is immediately available to all warehouses.

*** Global Services Layer

Highly available system management services common to all Snowflake
users, responsible for optimizing queries, scaling and managing
infrastructure, metadata caching, authentication, and security.

Snowflake is a global multi-tenancy service.

** Editions & Pricing
:PROPERTIES:
:ID:       9706ae40-c402-495c-8333-40c841bf2f99
:END:

*Topics:*

- Editions: Standard, Enterprise, Business Critical, Virtual Private Snowflake (VPS)
- Pricing model: credits for compute + storage + usage
- How edition differences affect features (e.g. multi-cluster, data protection)

*Standard*

*Enterprise* adds database failover, multi-cluster warehouses, and
additional data protection and encryption features.

*Business Critical*

*Virtual Private* is isolated from the global Snowflake program.

* Snowflake Objects & DDL Commands
:PROPERTIES:
:ID:       27495aa5-d586-461e-ab3c-65c9465f00c8
:END:

*Topics:*

- Databases, Schemas, Tables, Views
- External Tables, Streams, Tasks
- Sequences, Stages
- Examples of CREATE / ALTER / DROP
- Cloning & object versioning
- DDL = Data definition language

*Objects* in Snowflake allow nearly all aspects of the data platform to
be configured with unique access and usage restrictions, from the
*Organization* level down to tables and views.

*Account Objects:*

- Network Policy
- User
- Role
- Database => Schema
- Warehouse
- Share
- Resource Monitor

*Schema Objects:*

- Stage
- Pipe
- Procedure
- Function
- Table
- View
- Task
- Stream



** Object Naming Rules

The name of a database, schema, or table must be unique and start with
'~A-Z~', and are not case sensitive unless encased in double quotes.
Special characters can only be used within quotes.

** General DDL Commands

Data Definition Language (DDL) commands are used to manipulate objects
in Snowflake, including setting parameters on account and session objects.

Generally these are available:

- [[https://docs.snowflake.com/en/sql-reference/sql/use][USE]] <object>
- [[https://docs.snowflake.com/en/sql-reference/sql/create][CREATE]] <object>
- [[https://docs.snowflake.com/en/sql-reference/sql/alter][ALTER]] <object>
- [[https://docs.snowflake.com/en/sql-reference/sql/create-or-alter][CREATE OR ALTER]] <object>
- [[https://docs.snowflake.com/en/sql-reference/sql/drop][DROP]] <object>
- [[https://docs.snowflake.com/en/sql-reference/sql/show][SHOW]] <objects>
- [[https://docs.snowflake.com/en/sql-reference/sql/desc][DESCRIBE]] <object>
- [[https://docs.snowflake.com/en/sql-reference/sql/comment][COMMENT]]

** Databases

A database is associated with one account. See [[https://docs.snowflake.com/en/sql-reference/commands-database#database][docs]].

#+begin_src sql
CREATE DATABASE MY_DATABASE;

-- Cloned
CREATE DATABASE CLONED_DB CLONE MY_DATABASE;

-- Replica
CREATE DATABASE REPLICA_DB AS REPLICA OF MY_DATABASE
  DATA_RETENTION_TIME_IN_DAYS = 3;

-- From share object provided by external account
CREATE DATABASE SHARED_DB FROM SHARE S9DF89.SHARE;

#+end_src

** Schemas

A schema is associated with one database. See [[https://docs.snowflake.com/en/sql-reference/commands-database#schema][docs]].

#+begin_src sql
USE DATABASE MY_DATABASE;
CREATE SCHEMA MY_SCHEMA;

-- Cloned
CREATE SCHEMA CLONED_SCM CLONE MY_DATABASE.MY_SCHEMA;
#+end_src

** Tables

A table is associated with one schema. See [[https://docs.snowflake.com/en/sql-reference/commands-table#table][docs]].

- Tables are *permanent by default*, but can also be temporary,
  transient (no failsafes), or external (not managed in Snowflake).
- Standard accounts can set *time travel* on permanent tables to a day,
  and enterprise accounts can be set up to 90 days, which enables
  un-dropping the table and restoring from a particular timestamp.


** Views

- Views don't contribute to storage cost.
- Querying views that rely on droped tables will throw an error.
- Can be used to reveal a subset of table data.
- *Materialized* views are periodically refreshed and stores the results
  of the query independently from the source table.
- *Secure* views are only visible to authorized users.

* Data Loading & Unloading
:PROPERTIES:
:ID:       4d1dcea7-9c22-4c51-a70f-b6ee3dfb09b7
:END:

*Topics:*

- Stages: internal (user, table, named) vs external cloud stages
- Snowflake Documentation
- COPY INTO / bulk load
- Snowpipe (continuous ingestion)
- Snowflake Documentation
- Snowpipe Streaming
- Loading semi-structured data and schema inference

* Querying & DML
:PROPERTIES:
:ID:       a41532df-4d4c-460a-b6a0-692d2810513f
:END:

*Topics:*

- SELECT, INSERT, UPDATE, DELETE, MERGE
- Joins, subqueries, functions
- Working with semi-structured data (VARIANT, OBJECT, ARRAY)
- Window functions, CTEs, analytic SQL
- Transforming data in Snowflake

* Warehouses & Compute
:PROPERTIES:
:ID:       16b1100d-c08c-444c-ae93-a8bf16f629fb
:END:

*Topics:*

- What is a warehouse; required for queries / DML
- Snowflake Documentation
- Warehouse sizes and billing
- Snowflake Documentation
- Auto-suspend, auto-resume
- Multi-cluster warehouses
- Best practices for compute sizing & concurrency

** Performance & Cost Optimization
:PROPERTIES:
:ID:       bc077855-d82a-4d0c-a222-e1bc58bf5824
:END:

*Topics:*

- Choosing warehouse sizes vs concurrency
- Pruning / clustering / clustering keys
- Caching, result caching
- Query profiling / query history
- Avoiding overprovisioning / idle compute

* Security & Access Control
:PROPERTIES:
:ID:       6311ae74-372b-461d-8e05-375e489e2e5b
:END:

*Topics:*

- Account access
- Roles, users, grants, privileges
- Snowflake Documentation
- Object-level permissions
- Row access policies, masking policies
- Network / IP policies, secure views, encryption

Each *account* is created on specific *provider*, in a particular *region*,
as a single Snowflake *edition*. An *organization* can manage one or more
accounts for different departments, projects, or locations.

The ~GLOBALORGADMIN~ account can be used to create more accounts and
manage their lifecycle;

#+begin_src sql
USE ROLE GLOBALORGADMIN;

CREATE ACCOUNT analytics4
  ADMIN_NAME = admin7
  REGION = aws_us_west_2
  etc;

SHOW ACCOUNTS;
#+end_src

The short-form of the organization and account is shown in your URL.

#+begin_src
https://uslkjpw-sjl18827.snowflakecomputing.com/
        ------- --------
          Org.    Acct.
#+end_src

This URL will prompt you to login, then redirect you to *Snowsight*.

* Integration & Connectors
:PROPERTIES:
:ID:       c1a67b04-429f-47a8-aafe-6248093d0d33
:END:

*Topics:*

- JDBC, ODBC, Python connector
- Spark / Snowflake connector
- Kafka Connector
- BI tools (Tableau, Power BI, etc.)
- Data marketplace & data sharing

** Snowpark (Python, Java, Scala APIs)
:PROPERTIES:
:ID:       20601437-378d-4efc-bcc4-79fc37bb5647
:END:

Python is common - as the lingua franca of data scientists.

* Advanced Features
:PROPERTIES:
:ID:       5311cf05-ba3c-45ae-8ac5-cdf8f8146d4c
:END:

*Topics:*

- Time Travel & Fail-safe
- Zero-copy cloning
- Materialized Views
- Tasks & scheduled pipelines
- Search optimization service
- Streams & Change Data Capture (CDC)

* Tips, Best Practices & Gotchas
:PROPERTIES:
:ID:       1e1ad07a-59d2-4e30-b025-8ddf3505844b
:END:

*Topics:*

- Avoid leaving warehouses running unnecessarily
- For small queries, very large warehouses may not help
- Use clustering only when needed
- Be aware of billing granularity (per second)
- Watch out for too many small files in load
- Query patterns that can disrupt performance

* References & Further Reading
:PROPERTIES:
:ID:       ad44f0cb-efbf-44d8-bd07-c53538951428
:END:



Snowflake has tons of interesting documents in their [[https://www.snowflake.com/en/resources/][resource library]],
including migration advice, using Snowflake as a backing database for
agents, and much more.

*Topics:*

- Official Snowflake documentation (docs.snowflake.com)
- Snowflake Documentation
- Tutorials (“Snowflake in 20 minutes”)
- Snowflake Documentation
- Quickstarts & hands-on labs
- Snowflake Quickstarts
- SQL command reference
- Snowflake Documentation

* Footnotes

[fn:2] *EC2* or equivalent cloud-based virtual machines.

[fn:1] *Columnar Storage* is read-optimized, enabling quick seeking
through rows without having to read over the entire content of each
row, like a CSV or other row-oriented storage format.
